# üè¶ Projeto Banco PDI - Microsservi√ßos com Kafka e Elasticsearch

Este reposit√≥rio cont√©m o c√≥digo-fonte de um sistema banc√°rio simplificado, desenvolvido como parte de um Plano de Desenvolvimento Individual (PDI) focado no estudo e aplica√ß√£o de tecnologias de sistemas distribu√≠dos, com √™nfase no ecossistema do Elasticsearch.

O projeto simula opera√ß√µes de cria√ß√£o de contas e transfer√™ncias monet√°rias, utilizando uma arquitetura de microsservi√ßos robusta, resiliente e orientada a eventos.

---
### üéØ Alinhamento com os Objetivos do PDI

Este projeto foi desenhado para cumprir os seguintes objetivos de aprendizado:

* **1. Fundamentos do Elasticsearch:**
    * ‚úÖ **Conclu√≠do:** Atrav√©s da cria√ß√£o do `notificacao-service`, que consome eventos de transa√ß√µes do Kafka e os indexa em tempo real no √≠ndice `transacoes`, estabelecendo o pipeline de dados completo.

* **2. Aprofundamento em Consultas e An√°lise:**
    * ‚úÖ **Conclu√≠do:** Com a implementa√ß√£o da API de busca no `notificacao-service`, que exp√µe endpoints para buscas filtradas (filtros din√¢micos por conta e data), busca full-text e, principalmente, a API de agrega√ß√µes para analytics em tempo real (ex: total de gastos por conta).

* **3. Visualiza√ß√£o com Kibana:**
    * ‚úÖ **Conclu√≠do:** Com a cria√ß√£o de um dashboard interativo no Kibana, com gr√°ficos de pizza e s√©ries temporais que consomem os dados do Elasticsearch para fornecer insights visuais sobre as transa√ß√µes.

---
### üèõÔ∏è Arquitetura

O sistema √© composto por 4 microsservi√ßos principais e uma infraestrutura containerizada com Docker. A comunica√ß√£o entre os servi√ßos √© feita de forma s√≠ncrona (REST com Feign Client) e ass√≠ncrona (via eventos com Kafka).

**Fluxo Simplificado:**
`Cliente` -> `API Gateway` -> `Servi√ßos de Neg√≥cio` -> `Kafka` -> `Servi√ßo de Notifica√ß√£o` -> `Elasticsearch` -> `Kibana`

---
### üöÄ Tecnologias Utilizadas

* **Backend:**
    * Java 21 (com Virtual Threads habilitadas)
    * Spring Boot 3
    * Spring Cloud Gateway (API Gateway)
    * Spring Data JPA (Persist√™ncia Relacional)
    * Spring Data Elasticsearch (Busca e An√°lise)
    * OpenFeign (Comunica√ß√£o S√≠ncrona)
    * Resilience4j (Circuit Breaker)
* **Mensageria:**
    * Apache Kafka
* **Banco de Dados & Busca:**
    * PostgreSQL
    * Elasticsearch
* **Ferramentas e Infraestrutura:**
    * Docker & Docker Compose
    * Gradle (Build Tool)
    * Kibana (Visualiza√ß√£o)
    * Kafka UI (Monitoramento do Kafka)
    * Lombok

---
### ‚öôÔ∏è Como Executar o Projeto

**Pr√©-requisitos:**
* Java 21
* Docker e Docker Compose

**Passos:**
1.  **Clone o Reposit√≥rio:**
    ```sh
    git clone <URL_DO_SEU_REPOSITORIO>
    cd <PASTA_RAIZ_DO_PROJETO>
    ```

2.  **Inicie a Infraestrutura:**
    Este comando subir√° os containers do Postgres, Kafka, Elasticsearch e Kibana.
    ```sh
    docker-compose up -d
    ```

3.  **Construa o Projeto:**
    Este comando compilar√° todos os m√≥dulos.
    ```sh
    ./gradlew.bat clean build
    ```

4.  **Execute os Servi√ßos:**
    Abra um terminal para cada servi√ßo e execute o comando correspondente.

    * **Terminal 1 (Conta Service):**
        ```sh
        ./gradlew.bat :conta:bootRun
        ```
    * **Terminal 2 (Transa√ß√£o Service):**
        ```sh
        ./gradlew.bat :transacao:bootRun
        ```
    * **Terminal 3 (Notifica√ß√£o Service):**
        ```sh
        ./gradlew.bat :notificacao:bootRun
        ```
    * **Terminal 4 (API Gateway):**
        ```sh
        ./gradlew.bat :api-gateway:bootRun
        ```

A aplica√ß√£o estar√° pronta para ser usada!

---
### üìñ Documenta√ß√£o da API (Endpoints)

Todas as requisi√ß√µes devem ser feitas para o **API Gateway**: `http://localhost:8080`.

#### Servi√ßo de Contas (`/contas`)
| M√©todo | Rota | Descri√ß√£o |
| :--- | :--- | :--- |
| `POST` | `/contas` | Cria uma nova conta. |
| `GET` | `/contas/{id}` | Busca os detalhes de uma conta por ID. |

#### Servi√ßo de Transa√ß√µes (`/transacoes`)
| M√©todo | Rota | Descri√ß√£o |
| :--- | :--- | :--- |
| `POST` | `/transacoes` | Inicia uma nova transa√ß√£o. Requer o header `Idempotency-Key`. |

#### Servi√ßo de Busca (`/transacoes-search`)
| M√©todo | Rota | Descri√ß√£o |
| :--- | :--- | :--- |
| `GET` | `/transacoes-search` | Busca filtrada e paginada de transa√ß√µes. |
| `GET` | `/transacoes-search/busca` | Busca textual livre na descri√ß√£o das transa√ß√µes. |
| `GET` | `/transacoes-search/stats/gastos-por-conta-destino` | Agrega e retorna o total gasto por conta de destino. |

---
### üß™ Ambiente e Collection Postman

Para facilitar os testes, voc√™ pode baixar a collection completa da API e o arquivo de ambiente do Postman no link abaixo.

* **[üîó Baixar Arquivos do Postman (Collection + Environment)](https://drive.google.com/drive/folders/10QGD9_cyRip6ufS0HmKyoueP61tx6Vlk?usp=sharing)**

---
### üîé Como o Elasticsearch foi Utilizado

O Elasticsearch √© o cora√ß√£o da capacidade de an√°lise e consulta deste projeto, cumprindo os objetivos do PDI.

1.  **Pipeline de Dados em Tempo Real:** O `notificacao-service` atua como um consumidor do t√≥pico Kafka `transacoes.concluidas`. Assim que uma transa√ß√£o √© bem-sucedida, o evento √© capturado e o dado √© indexado quase instantaneamente no Elasticsearch.

2.  **Busca e An√°lise:** O Elasticsearch √© usado para duas finalidades principais:
    * **API de Busca:** Fornece uma API de busca poderosa e desacoplada do banco de dados relacional. Isso permite consultas complexas (filtros, pagina√ß√£o, busca textual) sem sobrecarregar o banco transacional.
    * **Analytics em Tempo Real:** A API de Agrega√ß√µes do Elasticsearch foi usada para criar o endpoint de estat√≠sticas (`/stats/gastos-por-conta-destino`), que realiza c√°lculos complexos (agrupamentos e somas) diretamente no motor de busca, de forma perform√°tica.

3.  **Visualiza√ß√£o:** Os dados indexados no Elasticsearch servem como fonte para o **Kibana**, onde foi constru√≠do um dashboard para monitorar e visualizar os indicadores de neg√≥cio (volume de transa√ß√µes, totais, etc.) de forma interativa.